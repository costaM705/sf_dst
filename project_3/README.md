# Проект 3. Рейтинг отеля по данным сайта Booking.
# EDA + Feature Engineering. Соревнование на Kaggle

![SkillFactory](../images/sf_logo.png) ![Booking.com](../images/booking_com_logo.png)

## Оглавление

[1. Описание проекта](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Описание-проекта)   
[2. Какой кейс решаем](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Какой-кейс-решаем)   
[3. Описание данных](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Описание-данных)   
[4. Этапы работы над проектом](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Этапы-работы-над-проектом)   
[5. Результат](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Результат)   
[6. Требования для работы](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Требования-для-работы)         
[7. Выводы](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Выводы)   

## Описание проекта

Представьте, что вы работаете дата-сайентистом в компании Booking. Одна из проблем компании — это нечестные отели, которые накручивают себе рейтинг. Одним из способов обнаружения таких отелей является построение модели, которая предсказывает рейтинг отеля. Поставлена задача создать такую модель, предсказывающую рейтинг отеля. Если предсказания модели сильно отличаются от фактического результата, то, возможно, отель ведёт себя нечестно, и его стоит проверить.

 :arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)      


## Какой кейс решаем

Цель проекта: построить модель на основе алгоритмов машинного обучения, которая предсказывает рейтинг отеля.

Задачи проекта:

1. Ознакомиться с входными данными.
2. Изучить пример машинного обучения (scikit-learn класс RandomForestRegressor, и закрепить LightAutoML).
3. Выполнить подготовку данных, которые будут использованы для обучения модели - формирование новые признаков, преобразование и извлечение данных из имеющихся.
4. Проверить эффективность предлагаемой модели, используя метрику MAPE.
5. Принять участие в соревнованиях на площадке Kaggle.com.   

Условия задания:
* Решение оформляется только в Jupyter Notebook.
* Решение оформляется в соответствии с ноутбуком-шаблоном на Kaggle.com.
* Не следует создавать много ячеек для решения задачи — это проявляет неудобства при проверке.
* Код на Python должен быть читаемым. Не забывать про отступы, разметку и комментарии в коде.
* Выводы по каждому этапу оформляются в формате Markdown в отдельной ячейке.

Метрики качества:
* Решение оформляется только в Jupyter Notebook.
* Решение оформляется в соответствии с ноутбуком-шаблоном.
* Качество кода (соблюдение стандартов оформления PEP-8, комментирование кода, README к проекту). Оформление проекта на GitHub, GitLab, Kaggle.
* Очистка данных.
* Исследование данных (качество визуализации, наличие идей, гипотез, комментариев).
* Генерация признаков.
* Отбор признаков.
* Преобразование признаков.
* Качество решения: результат метрики MAPE.

За каждый критерий можно получить **от 0 до 3 баллов**.

| Количество баллов | Критерии оценивания | 
|---|---| 
| 0 баллов | Задание не выполнено или результатами работы невозможно воспользоваться на практике | 
| 1 балл | Есть большие неточности в выполнении задания | 
| 2 балла | Задача решена, требуются минимальные доработки | 
| 3 балла | Задача решена полностью, результат можно использовать на практике | 

* Необходимо: ответить на контрольные вопросы, сдать проект на проверку, загрузив ноутбук-шаблон со своим решением на GitHub. Для того чтобы успешно сдать проект, **достаточно набрать 12 баллов**.

Максимальное количество баллов за задание — **21**.

Что практикуем:
* Учимся писать отличный код на Python.
* Учимся взаимодейстовать с международной платформой Kaggle.
* Учимся строить модель машинного обучения на международной платформе Kaggle и участвовать в соревнованиях.
* Учимся сравнивать эксперименты с точки зрения метрик, параметров.
* Учимся следить за моделью от создания до вывода в продакшен.
* Учимся делиться своим проектом, оставить проект приватным или сделать его общедоступным.
* Учимся эффективно работать с IDE VSCode.
* Повышаем квалификацию по методам преобразования и очистки данных.
* Повышаем квалификацию с GitHub.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)      

## Описание данных

В данном проекте первоначальные данные представлены в виде совокупного датасета размером: свыше 515000 строк, 16 столбцов, типа object, float64 и int64, в отдельных столбцах присутствуют пропуски и дубликаты. В связи с этим необходимо более детально проанализировать структуру первоначальных данных, сделать выводы о дальнейших преобразованиях. Построить обучающую модель, которая должна предсказывать рейтинг отеля по данным сайта Booking на основе имеющихся в датасете данных.

Датасеты:

* *hotels.csv* — первоначальные данные для исследования с учебной платформы Skillfactory, используется в предпроектной работе — [project_3a](https://github.com/costaM705/sf_data_science/blob/main/project_3/project_3a.ipynb).
* *hotels_train.csv* — первоначальные данные для исследования с Kaggle.com.
* *hotels_test.csv* — данные для валидации модели с Kaggle.com.
* *submission.csv* — результат обучения модели, представленный с Kaggle.com.
* *submission_rfr.csv* — результат обучения модели scikit-learn RandomForestRegressor.
* *submission_laml.csv* — результат обучения модели LightAutoML.

Первоначальная версия датасета **hotels_train.csv** содержит 17 полей со следующей информацией:

* *hotel_address* — адрес отеля.
* *review_date* — дата, когда рецензент разместил соответствующий отзыв.
* *average_score* — средний балл отеля, рассчитанный на основе последнего комментария за последний год.
* *hotel_name* — название отеля.
* *reviewer_nationality* — страна рецензента.
* *negative_review* — отрицательный отзыв, который рецензент дал отелю.
* *review_total_negative_word_counts* — общее количество слов в отрицательном отзыв.
* *positive_review* — положительный отзыв, который рецензент дал отелю.
* *review_total_positive_word_counts* — общее количество слов в положительном отзыве.
* *reviewer_score* — оценка, которую рецензент поставил отелю на основе своего опыта.
* *total_number_of_reviews_reviewer_has_given* — количество отзывов, которые рецензенты дали в прошлом.
* *total_number_of_reviews* — общее количество действительных отзывов об отеле.
* *tags* — теги, которые рецензент дал отелю.
* *days_since_review* — количество дней между датой проверки и датой очистки.
* *additional_number_of_scoring* — есть также некоторые гости, которые просто поставили оценку сервису, но не оставили отзыв. Это число указывает, сколько там действительных оценок без проверки.
* *lat* — географическая широта отеля.
* *lng* — географическая долгота отеля.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)        


## Этапы работы над проектом

* Ознакомление с описанием задачи.
* Знакомство с данными.
* Импортирование необходимых библиотек.
* Загрузка данных и объединение трейн и тестовых данных в один датасет для корректной одновременной обработки признаков.
* Изучение датасета на предмет наличия пропусков и типов данных.
* Обработка данных: извлечение данных из выборки, создание новых признаков.
* Очистка и отбор признаков: удаление признаков, на которых модель обучаться не будет, отбор признаков на основании мультиколлинеарности, а также отбор признаков по значимости, по 2 методикам — раздельно для категориальных ("хи-квадрат") и непрерывных признаков (ANOVA).
* Разделение данных для модели: выделение тестовой части, разделение тренингового датасета: 80% всех данных — на обучение, 20% данных — на валидацию, проверка размерности разделённых датасетов.
* Построение и обучение модели.
* Сравнение предсказанных значений с реальными, и оценка насколько они, в среднем, отличаются. В качестве метрики используется Mean Absolute Error (MAE) и Mean Absolute Percentage Error (MAPE).
* Проверка соответствия написанного кода стандарту PEP8.
* Оформление проекта.
* Загрузка кода на площадку Kaggle для участия в соревновании и дубликация на GitHub.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)        

## Результат

Ноутбук с решением: [project_3](https://github.com/costaM705/sf_data_science/blob/main/project_3/project_3.ipynb).      
Для обеспечения воспроизводимости кода можно воспользоваться: [requirements.txt](https://github.com/costaM705/sf_data_science/tree/main/project_3/requirements.txt).

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)         

## Требования для работы

* Основной интерпретатор — Python 3.9.9
* Дополнительные требования перечислены в requirements.txt (получены командой pip freeze > requirements.txt).
* Установка недостающих компонент:

        pip install -r requirements.txt

* В проекте используется:  
  * scikit-learn:

        pip install -U scikit-learn

  Документация по использованию scikit-learn — [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)

  * LightAutoML:

        pip install -U lightautoml   

  Документация по использованию LightAutoML — [GitHub LightAutoML](https://lightautoml.readthedocs.io/en/latest/index.html)

* Для работы с большими файлами используется надстройка GitHub — [Git LFS](https://git-lfs.github.com)

  Документация по использванию Git LFS — [Git LFS Documentation](https://github.com/git-lfs/git-lfs/tree/main/doc)

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)         

## Выводы

В процессе выполнения кейса первоначальные данные были:

* Внимательно изучены исходные данные и проанализированы.
* Проведена подготовка данных к использованию: очистка, преобразование, исключение, создание признаков.
* Проведён обучающий эксперимент, построены 2 обучающие модели.
* Построена обучающая модель, основанная на алгоритмах машинного обучения, которая предсказывает рейтинг отеля.
* Принято участие в соревновании по машинному обучению.
* Для обучения модели, были взяты 29 значимых признака — 14 категориальных и 15 числовых.

В результате был достигнут показатель МАРЕ:

* LightAutoML — 11.74853823 (на Kaggle — 11.83143)   
* RandomForestRegressor — 12.04987098 (на Kaggle — 12.13146)   

В лидерборде отображается общая оценка — 11.83143

Результат — 11-е место в лидерборде по состоянию на 01.06.2023 г.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)   


