# Проект 3. Рейтинг отеля по данным сайта Booking.
# EDA + Feature Engineering. Соревнование на Kaggle

![Booking.com](../images/booking_com_logo.png)

![SkillFactory](../images/sf_logo.png)

## Оглавление

[1. Описание проекта](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Описание-проекта)   
[2. Какой кейс решаем](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Какой-кейс-решаем)   
[3. Описание данных](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Описание-данных)   
[4. Этапы работы над проектом](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Этапы-работы-над-проектом)   
[5. Результат](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Результат)   
[6. Требования для работы](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Требования-для-работы)         
[7. Выводы](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Выводы)   

## Описание проекта

Представьте, что вы работаете дата-сайентистом в компании Booking. Одна из проблем компании — это нечестные отели, которые накручивают себе рейтинг. Одним из способов обнаружения таких отелей является построение модели, которая предсказывает рейтинг отеля. Поставлена задача создать такую модель, предсказывающую рейтинг отеля. Если предсказания модели сильно отличаются от фактического результата, то, возможно, отель ведёт себя нечестно, и его стоит проверить.

 :arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)      


## Какой кейс решаем

Цель проекта: построить модель на основе алгоритмов машинного обучения, которая предсказывает рейтинг отеля.

Задачи проекта:

1. Ознакомиться с входными данными
2. Изучить пример машинного обучения (scikit-learn класс RandomForestRegressor, и закрепить LightAutoML)
3. Выполнить подготовку данных, которые будут использованы для обучения модели - формирование новые признаков, преобразование и извлечение данных из имеющихся
4. Проверить эффективность предлагаемой модели, используя метрику MAPE
5. Принять участие в соревнованиях на площадке Kaggle.com   

Условия задания:
* Решение оформляется только в Jupyter Notebook.
* Решение оформляется в соответствии с ноутбуком-шаблоном на Kaggle.com.
* Не следует создавать много ячеек для решения задачи — это проявляет неудобства при проверке.
* Код на Python должен быть читаемым. Не забывать про отступы, разметку и комментарии в коде.
* Выводы по каждому этапу оформляются в формате Markdown в отдельной ячейке.

Метрики качества:
* Решение оформляется только в Jupyter Notebook.
* Решение оформляется в соответствии с ноутбуком-шаблоном.
* Качество кода (соблюдение стандартов оформления PEP-8, комментирование кода, README к проекту). Оформление проекта на GitHub, GitLab, Kaggle.
* Очистка данных.
* Исследование данных (качество визуализации, наличие идей, гипотез, комментариев).
* Генерация признаков.
* Отбор признаков.
* Преобразование признаков.
* Качество решения: результат метрики MAPE.

Что практикуем:
* Работу с данными и выполнение SQL-запросов.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)      

## Описание данных

* Таблица VACANCIES хранит данные по вакансиям.
* Таблица AREAS является справочником, в котором хранятся коды городов и их названия.
* Таблица EMPLOYERS является справочником со списокм работодателей.
* Таблица INDUSTRIES является справочником вариантов сфер детельности работодателей.
* Таблица EMPLOYERS_INDUSTRIES - дополнительная таблица, которая существует для связи между работодателями и сферами их деятельности.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)        


## Этапы работы над проектом

* Исследование структуры данных.
* Преобразование данных.
* Исследование зависимостей в данных.
* Очистка данных.
* Оформление GitHub.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)        

## Результат

Ноутбук с решением: [project_3](https://github.com/costaM705/sf_data_science/blob/main/project_3/project_3.ipynb).      
Для обеспечения воспроизводимости кода можно воспользоваться: [requirements.txt](https://github.com/costaM705/sf_data_science/tree/main/project_3/requirements.txt).

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)         

## Требования для работы

* Основной интерпретатор — Python 3.10.
* Дополнительные требования перечислены в requirements.txt (получены командой pip freeze > requirements.txt).
* Установка недостающих компонент:

        pip install -r requirements.txt

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)         

## Выводы

В данном проекте была проведена работа по исследованию и очистке данных на примере датасета, содержащего вакансии с сайта поиска вакансий hh.ru.
Решена часть бизнес-задачи и применена роль работника кадрового агенства.

:arrow_up:[к оглавлению](https://github.com/costaM705/sf_data_science/tree/main/project_3/README.md#Оглавление)   


